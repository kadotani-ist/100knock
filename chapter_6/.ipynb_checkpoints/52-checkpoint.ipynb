{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_features_dic(fname):\n",
    "    with open(fname) as file:\n",
    "        return {line.rstrip('\\n'): i for i, line in enumerate(file)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_queue(fname, features_dic):\n",
    "    with open(fname) as file:\n",
    "        lines = file.readlines()\n",
    "        queue_x = np.zeros([len(lines), len(features_dic)])\n",
    "        queue_y = np.zeros([len(lines), 4]) # One-hot表現: [b, t, e, m]\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            import re\n",
    "            from nltk.corpus import stopwords\n",
    "            import snowballstemmer\n",
    "            \n",
    "            line = line.rstrip('\\n')\n",
    "            category = line.strip('\\t')[0]\n",
    "            title = line.split('\\t')[1]\n",
    "            \n",
    "            # queue_xの処理\n",
    "            # 文字種の統一\n",
    "            title = title.lower()\n",
    "            \n",
    "            # 数字の置き換え -> 除去\n",
    "            title = re.sub(r'[0-9]+', '', title)\n",
    "            \n",
    "            # '-'を' 'に変換\n",
    "            title = title.replace('-', ' ')\n",
    "            \n",
    "            words = title.split()\n",
    "            \n",
    "            # ストップワードの除去\n",
    "            stop_words = stopwords.words('english')\n",
    "            words2 = [word for word in words if word not in stop_words]\n",
    "            words = words2\n",
    "            \n",
    "            # ステミング処理\n",
    "            stemmer = snowballstemmer.stemmer('english')\n",
    "            words2 = [stemmer.stemWord(word) for word in words]\n",
    "            words = words2\n",
    "            \n",
    "            # 記号の除去\n",
    "            words2 = [word for word in words if word.islower()]\n",
    "            words = words2\n",
    "            \n",
    "            for word in words:\n",
    "                if word in features_dic.keys():\n",
    "                    queue_x[i, features_dic[word]] = 1\n",
    "                    \n",
    "            # queue_yの処理\n",
    "            if category == 'b':\n",
    "                queue_y[i, 0] = 1\n",
    "            elif category == 't':\n",
    "                queue_y[i, 1] = 1\n",
    "            elif category == 'e':\n",
    "                queue_y[i, 2] = 1\n",
    "            elif category == 'm':\n",
    "                queue_y[i, 3] = 1\n",
    "                \n",
    "    return queue_x, queue_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(queue): # ソフトマックス関数\n",
    "    return np.exp(queue) / np.sum(np.exp(queue), axis = 1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(queue_x, queue_y, queue_w, vector_b):\n",
    "    phi = softmax(np.dot(queue_x, queue_w) + vector_b)\n",
    "    closs_entropy = -np.sum(queue_y * np.log(phi)) # 交差エントロピー\n",
    "    dw = -np.dot(queue_x.T, queue_y - phi)\n",
    "    db = -np.dot(np.ones([1, queue_y.shape[0]]), queue_y - phi)\n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(queue_x, queue_y, queue_w, vector_b, lr):\n",
    "    dw, db = caluculate_gradient(queue_x, queue_y, queue_w, vector_b)\n",
    "    queue_w -= lr * dw\n",
    "    vector_b -= lr * db\n",
    "    \n",
    "    return queue_w, vector_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def valid(queue_x, queue_y, queue_w, vector_b):\n",
    "    pred_queue_y = np.zeros(queue_y.shape)\n",
    "    phi = softmax(np.dot(queue_x, queue_w) + vector_b)\n",
    "    class_labels = np.argmax(phi, axis = 1)\n",
    "    correct_count = 0\n",
    "    \n",
    "    for i in range(len(queue_y)):\n",
    "        pred_queue_y[i, class_labels[i]] = 1\n",
    "    for i in range(len(queue_y)):\n",
    "        if np.all(queue_y[i, :] == pred_queue_y[i, :]):\n",
    "            correct_count += 1\n",
    "            \n",
    "    return correct_count / len(queue_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000] 0.9137931034482759\n",
      "[2000] 0.9160419790104948\n",
      "[3000] 0.9145427286356822\n",
      "\n",
      "RESULT\n",
      "[1166] 0.9167916041979011\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features_dic = make_features_dic('train.feature.txt')\n",
    "train_queue_x, train_queue_y = make_queue('train.txt', features_dic)\n",
    "valid_queue_x, valid_queue_y = make_queue('valid.txt', features_dic)\n",
    "lr = pow(10, -3) # 学習率: 検証の結果、最も精度が高かった数値\n",
    "queue_w = np.ones([len(features_dic), 4])\n",
    "vector_b = np.ones([1, 4])\n",
    "accuracy, best_accuracy, pre_best_accuracy = 0, 0, 0\n",
    "count = 1\n",
    "\n",
    "while True:\n",
    "    pre_queue_w = queue_w\n",
    "    pre_vector_b = vector_b\n",
    "    \n",
    "    queue_w, vector_b = train(train_queue_x, train_queue_y, pre_queue_w, pre_vector_b, lr)\n",
    "    accuracy = valid(valid_queue_x, valid_queue_y, queue_w, vector_b)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_queue_w = queue_w\n",
    "        best_vector_b = vector_b\n",
    "        best_accuracy = accuracy\n",
    "        best_count = count\n",
    "    if count % 1000 == 0:\n",
    "        print('[{0}] {1}'.format(count, accuracy))\n",
    "        if best_accuracy == pre_best_accuracy:\n",
    "            break\n",
    "        pre_best_accuracy = best_accuracy\n",
    "    count += 1\n",
    "print('')\n",
    "\n",
    "print('RESULT')\n",
    "print('[{0}] {1}'.format(best_count, best_accuracy))\n",
    "np.save('results/52_result', np.concatenate([best_queue_w, best_vector_b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
