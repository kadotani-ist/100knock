{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features_dic(fname):\n",
    "    with open(fname) as file:\n",
    "        return {line.rstrip('\\n'): i for i, line in enumerate(file)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_queue(fname, features_dic):\n",
    "    with open(fname) as file:\n",
    "        lines = file.readlines()\n",
    "        queue_x = np.zeros([len(lines), len(features_dic)])\n",
    "        queue_y = np.zeros([len(lines), 4]) # One-hot表現: [b, t, e, m]\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            import re\n",
    "            from nltk.corpus import stopwords\n",
    "            import snowballstemmer\n",
    "            \n",
    "            line = line.rstrip('\\n')\n",
    "            category = line.strip('\\t')[0]\n",
    "            title = line.split('\\t')[1]\n",
    "            \n",
    "            # queue_xの処理\n",
    "            # 文字種の統一\n",
    "            title = title.lower()\n",
    "            \n",
    "            # 数字の置き換え -> 除去\n",
    "            title = re.sub(r'[0-9]+', '', title)\n",
    "            \n",
    "            # '-'を' 'に変換\n",
    "            title = title.replace('-', ' ')\n",
    "            \n",
    "            words = title.split()\n",
    "            \n",
    "            # ストップワードの除去\n",
    "            stop_words = stopwords.words('english')\n",
    "            words2 = [word for word in words if word not in stop_words]\n",
    "            words = words2\n",
    "            \n",
    "            # ステミング処理\n",
    "            stemmer = snowballstemmer.stemmer('english')\n",
    "            words2 = [stemmer.stemWord(word) for word in words]\n",
    "            words = words2\n",
    "            \n",
    "            # 記号の除去\n",
    "            words2 = [word for word in words if word.islower()]\n",
    "            words = words2\n",
    "            \n",
    "            for word in words:\n",
    "                if word in features_dic.keys():\n",
    "                    queue_x[i, features_dic[word]] = 1\n",
    "                    \n",
    "            # queue_yの処理\n",
    "            if category == 'b':\n",
    "                queue_y[i, 0] = 1\n",
    "            elif category == 't':\n",
    "                queue_y[i, 1] = 1\n",
    "            elif category == 'e':\n",
    "                queue_y[i, 2] = 1\n",
    "            elif category == 'm':\n",
    "                queue_y[i, 3] = 1\n",
    "                \n",
    "    return queue_x, queue_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(queue): # ソフトマックス関数\n",
    "    return np.exp(queue) / np.sum(np.exp(queue), axis = 1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(queue_x, queue_y, queue_w, vector_b, rp):\n",
    "    phi = softmax(np.dot(queue_x, queue_w) + vector_b)\n",
    "    \n",
    "    vector_l2_norm = np.zeros(len(queue_w))\n",
    "    for i in range(len(queue_w)):\n",
    "        vector_l2_norm[i] = np.sqrt(np.sum(np.square(queue_w[i])))\n",
    "    l2 = (rp / 2) * np.sum(vector_l2_norm) # L2正則化項\n",
    "    \n",
    "    closs_entropy = -np.sum(queue_y * np.log(phi)) +l2 # 交差エントロピー\n",
    "    \n",
    "    l2_dw = np.zeros(queue_w.shape) # L2正則化項のwについての偏微分\n",
    "    for i in range(len(queue_w)):\n",
    "        for j in range(4):\n",
    "            l2_dw = (rp / 2) * (queue_w[i][j] / vector_l2_norm[i])\n",
    "    \n",
    "    dw = -np.dot(queue_x.T, queue_y - phi) + l2_dw\n",
    "    db = -np.dot(np.ones([1, queue_y.shape[0]]), queue_y - phi)\n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(queue_x, queue_y, queue_w, vector_b, lr, rp):\n",
    "    dw, db = calculate_gradient(queue_x, queue_y, queue_w, vector_b, rp)\n",
    "    queue_w -= lr * dw\n",
    "    vector_b -= lr * db\n",
    "    \n",
    "    return queue_w, vector_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(queue_x, queue_y, queue_w, vector_b):\n",
    "    pred_queue_y = np.zeros(queue_y.shape)\n",
    "    phi = softmax(np.dot(queue_x, queue_w) + vector_b)\n",
    "    class_labels = np.argmax(phi, axis = 1)\n",
    "    correct_count = 0\n",
    "    \n",
    "    for i in range(len(queue_y)):\n",
    "        pred_queue_y[i, class_labels[i]] = 1\n",
    "    for i in range(len(queue_y)):\n",
    "        if np.all(queue_y[i, :] == pred_queue_y[i, :]):\n",
    "            correct_count += 1\n",
    "            \n",
    "    return correct_count / len(queue_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(exponent):\n",
    "    import numpy as np\n",
    "    \n",
    "    features_dic = make_features_dic('train.feature.txt')\n",
    "    train_queue_x, train_queue_y = make_queue('train.txt', features_dic)\n",
    "    valid_queue_x, valid_queue_y = make_queue('valid.txt', features_dic)\n",
    "    lr = pow(10, -3) # 学習率: 検証の結果、最も精度が高かった数値\n",
    "    rp = pow(10, exponent) # 正則化パラメータ\n",
    "    queue_w = np.ones([len(features_dic), 4])\n",
    "    vector_b = np.ones([1, 4])\n",
    "    accuracy, best_accuracy, pre_best_accuracy = 0, 0, 0\n",
    "    count = 1\n",
    "    \n",
    "    while True:\n",
    "        pre_queue_w = queue_w\n",
    "        pre_vector_b = vector_b\n",
    "        \n",
    "        queue_w, vector_b = train(train_queue_x, train_queue_y, pre_queue_w, pre_vector_b, lr, rp)\n",
    "        accuracy = valid(valid_queue_x, valid_queue_y, queue_w, vector_b)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_queue_w = queue_w\n",
    "            best_vector_b = vector_b\n",
    "            best_accuracy = accuracy\n",
    "            best_count = count\n",
    "        if count % 1000 == 0:\n",
    "            if best_accuracy == pre_best_accuracy:\n",
    "                break\n",
    "            pre_best_accuracy = best_accuracy\n",
    "        count += 1\n",
    "    print('[{0}] {1}'.format(best_count, best_accuracy))\n",
    "            \n",
    "    return best_queue_w, best_vector_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(fname, queue_w, vector_b):\n",
    "    features_dic = make_features_dic('train.feature.txt')\n",
    "    queue_x, queue_y = make_queue(fname, features_dic)\n",
    "    accuracy = valid(queue_x, queue_y, queue_w, vector_b)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracys(exponent, fname, fname2, fname3):\n",
    "    queue_w, vector_b = make_model(exponent)\n",
    "    accuracy = get_accuracy(fname, queue_w, vector_b)\n",
    "    accuracy2 = get_accuracy(fname2, queue_w, vector_b)\n",
    "    accuracy3 = get_accuracy(fname3, queue_w, vector_b)\n",
    "    \n",
    "    vector_l2_norm = np.zeros(len(queue_w))\n",
    "    for i in range(len(queue_w)):\n",
    "        vector_l2_norm[i] = np.sqrt(np.sum(np.square(queue_w[i])))\n",
    "    print('パラメータの大きさ: {0}'.format(np.sum(vector_l2_norm)))\n",
    "    \n",
    "    return accuracy, accuracy2, accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正則化パラメータ: 10^0\n",
      "[1166] 0.9167916041979011\n",
      "パラメータの大きさ: 7317.690332357281\n",
      "学習データ: 0.9964426137427448\t検証データ: 0.9145427286356822\t評価データ: 0.9092953523238381\n",
      "\n",
      "正則化パラメータ: 10^1\n",
      "[1166] 0.9167916041979011\n",
      "パラメータの大きさ: 5443.30107012985\n",
      "学習データ: 0.9964426137427448\t検証データ: 0.9145427286356822\t評価データ: 0.9092953523238381\n",
      "\n",
      "正則化パラメータ: 10^2\n",
      "[1166] 0.9167916041979011\n",
      "パラメータの大きさ: 5443.699306763107\n",
      "学習データ: 0.9964426137427448\t検証データ: 0.9145427286356822\t評価データ: 0.9092953523238381\n",
      "\n",
      "正則化パラメータ: 10^3\n",
      "[1166] 0.9167916041979011\n",
      "パラメータの大きさ: 5443.737527636071\n",
      "学習データ: 0.9964426137427448\t検証データ: 0.9145427286356822\t評価データ: 0.9092953523238381\n",
      "\n",
      "正則化パラメータ: 10^4\n",
      "[1166] 0.9167916041979011\n",
      "パラメータの大きさ: 24037.96449278934\n",
      "学習データ: 0.9964426137427448\t検証データ: 0.9145427286356822\t評価データ: 0.9092953523238381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fname = 'train.txt'\n",
    "fname2 = 'valid.txt'\n",
    "fname3 = 'test.txt'\n",
    "rps = []\n",
    "train_accuracys = []\n",
    "valid_accuracys = []\n",
    "test_accuracys = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print('正則化パラメータ: 10^{0}'.format(i))\n",
    "    accuracy, accuracy2, accuracy3 = get_accuracys(i, fname, fname2, fname3)\n",
    "    rps.append(pow(10, i))\n",
    "    train_accuracys.append(accuracy)\n",
    "    valid_accuracys.append(accuracy2)\n",
    "    test_accuracys.append(accuracy3)\n",
    "    print('学習データ: {0}\\t検証データ: {1}\\t評価データ: {2}\\n'.format(accuracy, accuracy2, accuracy3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 22793 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 12540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 22793 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 23398 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 26908 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 35388 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 20385 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 23398 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 26908 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 35388 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 20385 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'AppleGothic'\n",
    "    \n",
    "plt.plot(rps, train_accuracys, color='r', label='学習データ')\n",
    "plt.plot(rps, valid_accuracys, color='g', label='検証データ')\n",
    "plt.plot(rps, test_accuracys, color='b', label='評価データ')\n",
    "plt.xscale('log')\n",
    "plt.title('正則化パラメータの変更')\n",
    "plt.xlabel('正則化パラメータ')\n",
    "plt.ylabel('正解率')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
