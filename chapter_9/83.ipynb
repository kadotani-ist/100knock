{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "83.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGU8nSnjxh6u",
        "colab_type": "code",
        "outputId": "ca42f468-5069-4979-e32b-ec652d154e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdpULQwoyUK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = F.relu(self.i2h(combined))\n",
        "        output = self.i2o(combined)\n",
        "        return output, hidden\n",
        "    \n",
        "    def initHidden(self, batch_size):\n",
        "        return torch.zeros(batch_size, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFFfcyCmy6VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_id_dic(fname):\n",
        "    id_dic = {}\n",
        "    \n",
        "    with open(fname) as file:\n",
        "        for i, line in enumerate(file, 1):\n",
        "            line = line.rstrip('\\n')\n",
        "            id_dic[line] = i\n",
        "            \n",
        "    return id_dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdQYUYVj0Eos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words2id(sentence, id_dic):\n",
        "    import re\n",
        "    import snowballstemmer\n",
        "    \n",
        "    words_id = []\n",
        "    \n",
        "    # 文字種の統一\n",
        "    sentence = sentence.lower()\n",
        "    \n",
        "    # 数字の置き換え\n",
        "    sentence = re.sub(r'[0-9]+', '0', sentence)\n",
        "    \n",
        "    # '-'を' 'に変換\n",
        "    sentence = sentence.replace('-', ' ')\n",
        "    \n",
        "    words = sentence.split()\n",
        "    \n",
        "    # ステミング処理\n",
        "    stemmer = snowballstemmer.stemmer('english')\n",
        "    words2 = [stemmer.stemWord(word) for word in words]\n",
        "    words = words2\n",
        "    \n",
        "    for word in words:\n",
        "        if word in id_dic.keys():\n",
        "            words_id.append(id_dic[word])\n",
        "        else:\n",
        "            words_id.append(0)\n",
        "            \n",
        "    return words_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q83reJ4h0Ny2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def id2vec(words_id, embeds):\n",
        "    words_vec = embeds(torch.Tensor(words_id).long())\n",
        "    \n",
        "    return words_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYXfPxY00UVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(fname, id_dic, embeds):\n",
        "    with open(fname) as file:\n",
        "        lines = file.readlines()\n",
        "        lines_vec = []\n",
        "        labels = np.zeros([len(lines), 1])\n",
        "        \n",
        "        for i, line in enumerate(lines):\n",
        "            \n",
        "            line = line.rstrip('\\n')\n",
        "            category = line.strip('\\t')[0]\n",
        "            title = line.split('\\t')[1]\n",
        "            \n",
        "            # lines_vecの処理\n",
        "            words_id = words2id(title, id_dic)\n",
        "            words_vec = id2vec(words_id, embeds)\n",
        "            lines_vec.append(words_vec)\n",
        "            \n",
        "            # labelsの処理\n",
        "            if category == 'b':\n",
        "                labels[i] = 0\n",
        "            elif category == 't':\n",
        "                labels[i] = 1\n",
        "            elif category == 'e':\n",
        "                labels[i] = 2\n",
        "            elif category == 'm':\n",
        "                labels[i] = 3\n",
        "    labels = torch.from_numpy(labels).long()\n",
        "                \n",
        "    return lines_vec, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INH7-bpY42G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(rnn, criterion, optimizer, batch_size, words_vec_batch, label_batch):\n",
        "    hidden = rnn.initHidden(batch_size)\n",
        "    rnn.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "    hidden = hidden.detach()\n",
        "    \n",
        "    for i in range(len(words_vec_batch)):\n",
        "        output, hidden = rnn(words_vec_batch[i].to(device), hidden.to(device))\n",
        "    loss = criterion(output, label_batch.to(device))\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTBw-IAh4Pja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loss_and_accyracy(rnn, criterion, lines_vec, labels):\n",
        "    running_loss = 0\n",
        "    correct_count = 0\n",
        "    \n",
        "    for words_vec, label in zip(lines_vec, labels):\n",
        "        words_vec_batch, label_batch = batch_process([words_vec], [label])\n",
        "        hidden = rnn.initHidden(1)\n",
        "        \n",
        "        for i in range(len(words_vec_batch)):\n",
        "            output, hidden = rnn(words_vec_batch[i].to(device), hidden.to(device))\n",
        "        loss = criterion(output, label.to(device))\n",
        "        running_loss += loss\n",
        "        pre_label = torch.max(output, 1)[1]\n",
        "        if pre_label == label.to(device):\n",
        "            correct_count += 1\n",
        "            \n",
        "    return running_loss / len(labels), correct_count / len(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0tSYT7r4R7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_process(words_vec_list, label_list):\n",
        "    # words_vec_batchの処理\n",
        "    len_max = 0\n",
        "    for words_vec in words_vec_list:\n",
        "        if words_vec.size()[0] > len_max:\n",
        "            len_max = words_vec.size()[0]\n",
        "    words_vec_batch = torch.zeros(len_max, len(words_vec_list), 300)\n",
        "    for i in range(len(words_vec_list)):\n",
        "        for j in range(len(words_vec_list[i])):\n",
        "            words_vec_batch[len_max - len(words_vec_list[i]) + j, i, :] = words_vec_list[i][j]\n",
        "        \n",
        "    # label_batchの処理\n",
        "    label_batch = torch.zeros(len(label_list)).long()\n",
        "    for i, label in enumerate(label_list):\n",
        "        label_batch[i] = label\n",
        "        \n",
        "    return words_vec_batch, label_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DygKB4NTAzBn",
        "colab_type": "code",
        "outputId": "34218df2-0ffe-40bf-f4af-a992b0189b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('{0}\\n'.format(device))\n",
        "\n",
        "rnn = RNN(300, 50, 4).to(device) # RNN(d_w, d_h, L)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(rnn.parameters(), lr=pow(10, -2)) # lr: 検証の結果、10エポック目で最も精度が高かった数値\n",
        "\n",
        "id_dic = make_id_dic('drive/My Drive/Colab Notebooks/100_knocks/chapter_6/train.feature.txt')\n",
        "embeds = nn.Embedding(len(id_dic)+1, 300)\n",
        "lines_vec, labels = make_dataset('drive/My Drive/Colab Notebooks/100_knocks/chapter_6/train.txt', id_dic, embeds)\n",
        "lines_vec_test, labels_test = make_dataset('drive/My Drive/Colab Notebooks/100_knocks/chapter_6/test.txt', id_dic, embeds)\n",
        "batch_size = 8\n",
        "\n",
        "for epoch in range(10):\n",
        "    words_vec_list = []\n",
        "    label_list = []\n",
        "    \n",
        "    for i, dataset in enumerate(zip(lines_vec, labels), 1):\n",
        "        words_vec_list.append(dataset[0])\n",
        "        label_list.append(dataset[1])\n",
        "        \n",
        "        if i % batch_size == 0 or i == len(lines_vec):\n",
        "            words_vec_batch, label_batch = batch_process(words_vec_list, label_list)\n",
        "            train(rnn, criterion, optimizer, len(words_vec_list), words_vec_batch, label_batch)\n",
        "            words_vec_list = []\n",
        "            label_list = []\n",
        "            \n",
        "    loss_train, accuracy_train = get_loss_and_accyracy(rnn, criterion, lines_vec, labels)\n",
        "    loss_test, accuracy_test = get_loss_and_accyracy(rnn, criterion, lines_vec_test, labels_test)\n",
        "    print('[{0}] 訓練データ上の損失: {1}\\t訓練データ上の正解率: {2}\\t評価データ上の損失: {3}\\t評価データ上の正解率: {4}'.format(epoch + 1, loss_train, accuracy_train, loss_test, accuracy_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "\n",
            "[1] 訓練データ上の損失: 0.9523890018463135\t訓練データ上の正解率: 0.6196405167571616\t評価データ上の損失: 1.054468035697937\t評価データ上の正解率: 0.5884557721139431\n",
            "[2] 訓練データ上の損失: 0.821818470954895\t訓練データ上の正解率: 0.6797416214192099\t評価データ上の損失: 0.9685491919517517\t評価データ上の正解率: 0.6356821589205397\n",
            "[3] 訓練データ上の損失: 0.6597511172294617\t訓練データ上の正解率: 0.7570679648005991\t評価データ上の損失: 0.8244378566741943\t評価データ上の正解率: 0.7076461769115442\n",
            "[4] 訓練データ上の損失: 0.5194805264472961\t訓練データ上の正解率: 0.8061224489795918\t評価データ上の損失: 0.7122222781181335\t評価データ上の正解率: 0.7586206896551724\n",
            "[5] 訓練データ上の損失: 0.45064449310302734\t訓練データ上の正解率: 0.8348623853211009\t評価データ上の損失: 0.6739144325256348\t評価データ上の正解率: 0.767616191904048\n",
            "[6] 訓練データ上の損失: 0.39617297053337097\t訓練データ上の正解率: 0.8559258565811646\t評価データ上の損失: 0.6396747827529907\t評価データ上の正解率: 0.7841079460269865\n",
            "[7] 訓練データ上の損失: 0.3454422354698181\t訓練データ上の正解率: 0.8737127878674406\t評価データ上の損失: 0.6308897137641907\t評価データ上の正解率: 0.7796101949025487\n",
            "[8] 訓練データ上の損失: 0.3047354519367218\t訓練データ上の正解率: 0.8893465643137989\t評価データ上の損失: 0.6274599432945251\t評価データ上の正解率: 0.7833583208395802\n",
            "[9] 訓練データ上の損失: 0.30928680300712585\t訓練データ上の正解率: 0.8852274854896087\t評価データ上の損失: 0.6449908018112183\t評価データ上の正解率: 0.7773613193403298\n",
            "[10] 訓練データ上の損失: 0.2509443163871765\t訓練データ上の正解率: 0.91069088185733\t評価データ上の損失: 0.6467059850692749\t評価データ上の正解率: 0.7758620689655172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd5FvJyv3pIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}