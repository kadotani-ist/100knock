{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../chapter_7/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, trial, d_h):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        num_layer = trial.suggest_int('num_layer', 1, 4)\n",
    "        \n",
    "        layers = []\n",
    "        num_input = d_h\n",
    "        num_output_last = 4\n",
    "        \n",
    "        for i in range(num_layer):\n",
    "            power_two = 1\n",
    "            \n",
    "            while power_two < num_input:\n",
    "                power_two *= 2\n",
    "            if i == num_layer-1:\n",
    "                num_output = num_output_last\n",
    "            else:\n",
    "                num_output = power_two / 2\n",
    "            layers.append(nn.Linear(int(num_input), int(num_output)))\n",
    "            num_input = num_output\n",
    "            \n",
    "        self.conv1 = nn.Conv2d(1, 50, (3, 300), padding=(1, 0))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        words_len = x.size(2)\n",
    "        \n",
    "        x =  F.relu(self.conv1(x)).squeeze(3)\n",
    "        x = F.max_pool2d(x, (1, words_len)).squeeze(2)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == len(self.layers) - 1:\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = F.relu(layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_id_dic(fname):\n",
    "    id_dic = {}\n",
    "    \n",
    "    with open(fname) as file:\n",
    "        for i, line in enumerate(file, 1):\n",
    "            line = line.rstrip('\\n')\n",
    "            id_dic[line] = i\n",
    "            \n",
    "    return id_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2id(sentence, id_dic):\n",
    "    import re\n",
    "    import snowballstemmer\n",
    "    \n",
    "    words_id = []\n",
    "    \n",
    "    # 文字種の統一\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # 数字の置き換え\n",
    "    sentence = re.sub(r'[0-9]+', '0', sentence)\n",
    "    \n",
    "    # '-'を' 'に変換\n",
    "    sentence = sentence.replace('-', ' ')\n",
    "    \n",
    "    words = sentence.split()\n",
    "    \n",
    "    # ステミング処理\n",
    "    stemmer = snowballstemmer.stemmer('english')\n",
    "    words2 = [stemmer.stemWord(word) for word in words]\n",
    "    words = words2\n",
    "    \n",
    "    for word in words:\n",
    "        if word in id_dic.keys():\n",
    "            words_id.append(id_dic[word])\n",
    "        else:\n",
    "            words_id.append(0)\n",
    "            \n",
    "    return words_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2vec(words_id, id_dic):\n",
    "    words_vec = []\n",
    "    \n",
    "    for id in words_id:\n",
    "        word_list = [k for k, v in id_dic.items() if v == id]\n",
    "        if len(word_list) > 0:\n",
    "            try:\n",
    "                words_vec.append(torch.from_numpy(model[word_list[0]]).view(1,-1))\n",
    "            except KeyError:\n",
    "                words_vec.append(torch.zeros(1, 300))\n",
    "        else:\n",
    "            words_vec.append(torch.zeros(1, 300))\n",
    "    \n",
    "    return torch.cat(words_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(fname, id_dic):\n",
    "    with open(fname) as file:\n",
    "        lines = file.readlines()\n",
    "        lines_vec = []\n",
    "        labels = np.zeros([len(lines), 1])\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            \n",
    "            line = line.rstrip('\\n')\n",
    "            category = line.strip('\\t')[0]\n",
    "            title = line.split('\\t')[1]\n",
    "            \n",
    "            # lines_vecの処理\n",
    "            words_id = words2id(title, id_dic)\n",
    "            words_vec = id2vec(words_id, id_dic)\n",
    "            lines_vec.append(words_vec)\n",
    "            \n",
    "            # labelsの処理\n",
    "            if category == 'b':\n",
    "                labels[i] = 0\n",
    "            elif category == 't':\n",
    "                labels[i] = 1\n",
    "            elif category == 'e':\n",
    "                labels[i] = 2\n",
    "            elif category == 'm':\n",
    "                labels[i] = 3\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "                \n",
    "    return lines_vec, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cnn, criterion, optimizer, words_vec, label):\n",
    "    cnn.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = cnn(words_vec.unsqueeze(0).unsqueeze(0))\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_accyracy(cnn, criterion, lines_vec, labels):\n",
    "    running_loss = 0\n",
    "    correct_count = 0\n",
    "    \n",
    "    for words_vec, label in zip(lines_vec, labels):\n",
    "        output = cnn(words_vec.unsqueeze(0).unsqueeze(0))\n",
    "        loss = criterion(output, label)\n",
    "        running_loss += loss\n",
    "        pre_label = torch.max(output, 1)[1]\n",
    "        if pre_label == label:\n",
    "            correct_count += 1\n",
    "            \n",
    "    return running_loss / len(labels), correct_count / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(trial, cnn):\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    wd = trial.suggest_loguniform('weight_decay', 1e-11, 1e-7)\n",
    "    \n",
    "    optimizer = optim.SGD(cnn.parameters(), lr=lr, weight_decay = wd)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(cnn, criterion, optimizer, lines_vec, labels, lines_vec_test, labels_test):\n",
    "    for epoch in range(10):\n",
    "        for words_vec, label in zip(lines_vec, labels):\n",
    "            train(cnn, criterion, optimizer, words_vec, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    d_h = 50 # d_h: 畳み込み演算後の各時刻のベクトルの次元数\n",
    "    cnn = Net(trial, d_h)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = make_optimizer(trial, cnn)\n",
    "    \n",
    "    id_dic = make_id_dic('../chapter_6/train.feature.txt')\n",
    "    lines_vec, labels = make_dataset('../chapter_6/train.txt', id_dic)\n",
    "    lines_vec_test, labels_test = make_dataset('../chapter_6/test.txt', id_dic)\n",
    "    \n",
    "    train_all(cnn, criterion, optimizer, lines_vec, labels, lines_vec_test, labels_test)\n",
    "    \n",
    "    loss_test, accuracy_test = get_loss_and_accyracy(cnn, criterion, lines_vec_test, labels_test)\n",
    "    \n",
    "    return 1 - accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n",
      "[I 2020-04-30 19:50:45,301] Finished trial#0 with value: 0.5809595202398801 with parameters: {'num_layer': 4, 'learning_rate': 5.0789136669157204e-05, 'weight_decay': 1.731946870163098e-08}. Best is trial#0 with value: 0.5809595202398801.\n",
      "[I 2020-04-30 19:53:28,516] Finished trial#1 with value: 0.5074962518740629 with parameters: {'num_layer': 2, 'learning_rate': 1.4855639948409303e-05, 'weight_decay': 1.7515473024875947e-11}. Best is trial#1 with value: 0.5074962518740629.\n",
      "[I 2020-04-30 19:55:54,073] Finished trial#2 with value: 0.25337331334332835 with parameters: {'num_layer': 1, 'learning_rate': 0.00010356358897314089, 'weight_decay': 6.5448868034125844e-09}. Best is trial#2 with value: 0.25337331334332835.\n",
      "[I 2020-04-30 19:58:16,427] Finished trial#3 with value: 0.1296851574212894 with parameters: {'num_layer': 1, 'learning_rate': 0.06059216879820546, 'weight_decay': 2.4983708748477233e-09}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:00:52,748] Finished trial#4 with value: 0.2646176911544228 with parameters: {'num_layer': 2, 'learning_rate': 9.202407861254297e-05, 'weight_decay': 1.463260513660292e-11}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:03:22,403] Finished trial#5 with value: 0.13043478260869568 with parameters: {'num_layer': 1, 'learning_rate': 0.006371647518985099, 'weight_decay': 3.48292729926222e-08}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:06:28,645] Finished trial#6 with value: 0.5809595202398801 with parameters: {'num_layer': 4, 'learning_rate': 4.024557431177698e-05, 'weight_decay': 1.468805920481883e-11}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:09:32,796] Finished trial#7 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 8.010921850256836e-05, 'weight_decay': 1.9715713623898198e-08}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:12:10,453] Finished trial#8 with value: 0.13343328335832083 with parameters: {'num_layer': 1, 'learning_rate': 0.0018681988575215188, 'weight_decay': 2.4378692586947462e-09}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:14:56,287] Finished trial#9 with value: 0.13193403298350825 with parameters: {'num_layer': 2, 'learning_rate': 0.0017431001701115286, 'weight_decay': 1.0064159460471738e-09}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:17:51,825] Finished trial#10 with value: 0.24587706146926536 with parameters: {'num_layer': 3, 'learning_rate': 0.05955514301588629, 'weight_decay': 1.438577170899218e-10}. Best is trial#3 with value: 0.1296851574212894.\n",
      "[I 2020-04-30 20:20:24,197] Finished trial#11 with value: 0.12518740629685154 with parameters: {'num_layer': 1, 'learning_rate': 0.04174225565117942, 'weight_decay': 9.460864274969458e-08}. Best is trial#11 with value: 0.12518740629685154.\n",
      "[I 2020-04-30 20:22:58,074] Finished trial#12 with value: 0.1581709145427287 with parameters: {'num_layer': 1, 'learning_rate': 0.0963155542505559, 'weight_decay': 1.5808165273588578e-10}. Best is trial#11 with value: 0.12518740629685154.\n",
      "[I 2020-04-30 20:25:50,492] Finished trial#13 with value: 0.11469265367316339 with parameters: {'num_layer': 1, 'learning_rate': 0.01848254768201811, 'weight_decay': 6.180583548358922e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:28:32,864] Finished trial#14 with value: 0.1356821589205397 with parameters: {'num_layer': 2, 'learning_rate': 0.014800944271969655, 'weight_decay': 8.60839370505841e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:31:15,125] Finished trial#15 with value: 0.1274362818590704 with parameters: {'num_layer': 1, 'learning_rate': 0.015514125876543133, 'weight_decay': 9.128586636145457e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:34:05,472] Finished trial#16 with value: 0.16641679160419787 with parameters: {'num_layer': 2, 'learning_rate': 0.013163619839420113, 'weight_decay': 5.663414228443771e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:37:11,943] Finished trial#17 with value: 0.16941529235382313 with parameters: {'num_layer': 3, 'learning_rate': 0.004111335419851703, 'weight_decay': 5.5592733228883735e-09}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:39:36,267] Finished trial#18 with value: 0.15967016491754127 with parameters: {'num_layer': 1, 'learning_rate': 0.0005864158019620447, 'weight_decay': 9.70196807925115e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:42:21,543] Finished trial#19 with value: 0.14467766116941527 with parameters: {'num_layer': 2, 'learning_rate': 0.03723300699397854, 'weight_decay': 1.73288045783041e-10}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:44:55,265] Finished trial#20 with value: 0.16116941529235385 with parameters: {'num_layer': 1, 'learning_rate': 0.000521302115342382, 'weight_decay': 1.7511364946403154e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:47:32,035] Finished trial#21 with value: 0.12368815592203897 with parameters: {'num_layer': 1, 'learning_rate': 0.02600786082120818, 'weight_decay': 4.72315851546221e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:50:08,036] Finished trial#22 with value: 0.12443778110944526 with parameters: {'num_layer': 1, 'learning_rate': 0.029437764933994567, 'weight_decay': 3.19688137654836e-08}. Best is trial#13 with value: 0.11469265367316339.\n",
      "[I 2020-04-30 20:52:33,753] Finished trial#23 with value: 0.1139430284857571 with parameters: {'num_layer': 1, 'learning_rate': 0.024670094506987084, 'weight_decay': 3.4607784842573655e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 20:55:30,314] Finished trial#24 with value: 0.13268365817091454 with parameters: {'num_layer': 2, 'learning_rate': 0.005835204037656891, 'weight_decay': 8.512520899832404e-09}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 20:58:11,692] Finished trial#25 with value: 0.11619190404797597 with parameters: {'num_layer': 1, 'learning_rate': 0.017094523854141706, 'weight_decay': 5.091754111139368e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:00:41,962] Finished trial#26 with value: 0.14017991004497754 with parameters: {'num_layer': 1, 'learning_rate': 0.09659206376075302, 'weight_decay': 1.124002085414428e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:03:27,889] Finished trial#27 with value: 0.1296851574212894 with parameters: {'num_layer': 2, 'learning_rate': 0.009030580259220582, 'weight_decay': 3.369632259817589e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:05:57,213] Finished trial#28 with value: 0.12668665667166412 with parameters: {'num_layer': 1, 'learning_rate': 0.004243138830581384, 'weight_decay': 3.7184290542553257e-09}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:08:37,270] Finished trial#29 with value: 0.12293853073463268 with parameters: {'num_layer': 1, 'learning_rate': 0.0023641338512690644, 'weight_decay': 1.748800561502972e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:11:46,403] Finished trial#30 with value: 0.13418290854572712 with parameters: {'num_layer': 4, 'learning_rate': 0.021529760291352014, 'weight_decay': 4.152728568060844e-10}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:14:30,071] Finished trial#31 with value: 0.13118440779610197 with parameters: {'num_layer': 1, 'learning_rate': 0.002270608618973826, 'weight_decay': 1.8107492843094716e-08}. Best is trial#23 with value: 0.1139430284857571.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-30 21:17:06,461] Finished trial#32 with value: 0.11544227886056968 with parameters: {'num_layer': 1, 'learning_rate': 0.009580012264652788, 'weight_decay': 5.739438899915268e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:19:36,021] Finished trial#33 with value: 0.1139430284857571 with parameters: {'num_layer': 1, 'learning_rate': 0.008700213345486478, 'weight_decay': 7.431015319395308e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:22:26,729] Finished trial#34 with value: 0.13418290854572712 with parameters: {'num_layer': 2, 'learning_rate': 0.00831104408284212, 'weight_decay': 6.492417923420167e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:25:06,799] Finished trial#35 with value: 0.15292353823088456 with parameters: {'num_layer': 1, 'learning_rate': 0.0007358048950142827, 'weight_decay': 2.6434621077041074e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:27:33,949] Finished trial#36 with value: 0.13043478260869568 with parameters: {'num_layer': 1, 'learning_rate': 0.06481338987435334, 'weight_decay': 1.199971077017171e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:30:21,237] Finished trial#37 with value: 0.23313343328335834 with parameters: {'num_layer': 2, 'learning_rate': 0.00028297613906662393, 'weight_decay': 4.764860593362246e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:32:54,369] Finished trial#38 with value: 0.12518740629685154 with parameters: {'num_layer': 1, 'learning_rate': 0.003512851247733936, 'weight_decay': 4.478860302094247e-11}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:35:33,016] Finished trial#39 with value: 0.11844077961019495 with parameters: {'num_layer': 1, 'learning_rate': 0.009285328488031954, 'weight_decay': 2.4775564019688675e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:38:22,481] Finished trial#40 with value: 0.13793103448275867 with parameters: {'num_layer': 2, 'learning_rate': 0.04667389186446935, 'weight_decay': 1.7430341157396485e-09}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:40:51,814] Finished trial#41 with value: 0.12593703148425783 with parameters: {'num_layer': 1, 'learning_rate': 0.020844127017397046, 'weight_decay': 6.048316330004437e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:43:25,266] Finished trial#42 with value: 0.12443778110944526 with parameters: {'num_layer': 1, 'learning_rate': 0.01134436893419784, 'weight_decay': 4.2661078957846806e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:46:01,768] Finished trial#43 with value: 0.11769115442278866 with parameters: {'num_layer': 1, 'learning_rate': 0.00585520429914529, 'weight_decay': 9.614230877939925e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:48:34,047] Finished trial#44 with value: 0.12368815592203897 with parameters: {'num_layer': 1, 'learning_rate': 0.01792564822497666, 'weight_decay': 6.652644069009872e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:50:52,919] Finished trial#45 with value: 0.11994002998500752 with parameters: {'num_layer': 1, 'learning_rate': 0.03189747120784189, 'weight_decay': 1.1457954951832953e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:53:00,164] Finished trial#46 with value: 0.14467766116941527 with parameters: {'num_layer': 1, 'learning_rate': 0.09856964696249049, 'weight_decay': 2.729217318913408e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:54:46,621] Finished trial#47 with value: 0.13643178410794599 with parameters: {'num_layer': 1, 'learning_rate': 0.0014212642480403237, 'weight_decay': 9.793213056086536e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:56:44,946] Finished trial#48 with value: 0.14692653673163414 with parameters: {'num_layer': 2, 'learning_rate': 0.06860051142250674, 'weight_decay': 6.331186115194688e-09}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 21:58:37,691] Finished trial#49 with value: 0.12518740629685154 with parameters: {'num_layer': 1, 'learning_rate': 0.01307889342442508, 'weight_decay': 3.8277535849001466e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:00:26,597] Finished trial#50 with value: 0.11919040479760123 with parameters: {'num_layer': 1, 'learning_rate': 0.0071075541565086406, 'weight_decay': 5.738790314135442e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:02:18,843] Finished trial#51 with value: 0.12218890554722639 with parameters: {'num_layer': 1, 'learning_rate': 0.004805644290941464, 'weight_decay': 7.481036123031156e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:04:10,955] Finished trial#52 with value: 0.13118440779610197 with parameters: {'num_layer': 1, 'learning_rate': 0.003243941858903448, 'weight_decay': 9.769931388827013e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:06:00,675] Finished trial#53 with value: 0.11994002998500752 with parameters: {'num_layer': 1, 'learning_rate': 0.0063441159028610385, 'weight_decay': 9.319368604733553e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:07:50,232] Finished trial#54 with value: 0.5412293853073463 with parameters: {'num_layer': 1, 'learning_rate': 1.1483956258544142e-05, 'weight_decay': 3.9681401356938395e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:09:43,488] Finished trial#55 with value: 0.1281859070464768 with parameters: {'num_layer': 1, 'learning_rate': 0.016148240701124524, 'weight_decay': 2.485630546464995e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:11:36,444] Finished trial#56 with value: 0.12518740629685154 with parameters: {'num_layer': 1, 'learning_rate': 0.02496160420949343, 'weight_decay': 9.998810323755446e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:13:24,482] Finished trial#57 with value: 0.14542728635682156 with parameters: {'num_layer': 1, 'learning_rate': 0.04376226781918009, 'weight_decay': 5.025508429891244e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:15:26,335] Finished trial#58 with value: 0.14392803598200898 with parameters: {'num_layer': 2, 'learning_rate': 0.01126959142138453, 'weight_decay': 7.268175250800493e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:17:35,458] Finished trial#59 with value: 0.16566716641679158 with parameters: {'num_layer': 3, 'learning_rate': 0.0013010210353584857, 'weight_decay': 1.505930963967922e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:19:27,683] Finished trial#60 with value: 0.12293853073463268 with parameters: {'num_layer': 1, 'learning_rate': 0.00612589704196158, 'weight_decay': 3.16006709781951e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:21:20,651] Finished trial#61 with value: 0.1289355322338831 with parameters: {'num_layer': 1, 'learning_rate': 0.00891540728361553, 'weight_decay': 2.1601639519491664e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:23:13,358] Finished trial#62 with value: 0.11619190404797597 with parameters: {'num_layer': 1, 'learning_rate': 0.010218866253489068, 'weight_decay': 4.2271851225151686e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:25:06,460] Finished trial#63 with value: 0.11919040479760123 with parameters: {'num_layer': 1, 'learning_rate': 0.020365231312029337, 'weight_decay': 4.349876555726609e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:26:58,618] Finished trial#64 with value: 0.1281859070464768 with parameters: {'num_layer': 1, 'learning_rate': 0.03436718633657863, 'weight_decay': 7.136372507833325e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:28:52,345] Finished trial#65 with value: 0.11619190404797597 with parameters: {'num_layer': 1, 'learning_rate': 0.012914598278851707, 'weight_decay': 3.334754260114158e-08}. Best is trial#23 with value: 0.1139430284857571.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-30 22:30:44,652] Finished trial#66 with value: 0.1214392803598201 with parameters: {'num_layer': 1, 'learning_rate': 0.014035979438997965, 'weight_decay': 1.3310450728646295e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:32:37,428] Finished trial#67 with value: 0.11994002998500752 with parameters: {'num_layer': 1, 'learning_rate': 0.00270370891973323, 'weight_decay': 4.4118452013256474e-09}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:34:27,100] Finished trial#68 with value: 0.1281859070464768 with parameters: {'num_layer': 1, 'learning_rate': 0.025279166944358052, 'weight_decay': 8.690810072551375e-09}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:36:20,161] Finished trial#69 with value: 0.13193403298350825 with parameters: {'num_layer': 1, 'learning_rate': 0.055243463744373125, 'weight_decay': 3.4116534439631504e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:38:14,467] Finished trial#70 with value: 0.11544227886056968 with parameters: {'num_layer': 1, 'learning_rate': 0.010644994696169403, 'weight_decay': 2.0174340489905545e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:40:09,334] Finished trial#71 with value: 0.12293853073463268 with parameters: {'num_layer': 1, 'learning_rate': 0.010205075244898353, 'weight_decay': 2.1757841871892627e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:42:03,801] Finished trial#72 with value: 0.12593703148425783 with parameters: {'num_layer': 1, 'learning_rate': 0.016069693727390356, 'weight_decay': 5.3104012402689185e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:43:55,956] Finished trial#73 with value: 0.11844077961019495 with parameters: {'num_layer': 1, 'learning_rate': 0.004698929180976834, 'weight_decay': 3.5408891786138006e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:45:49,701] Finished trial#74 with value: 0.1139430284857571 with parameters: {'num_layer': 1, 'learning_rate': 0.008013136187420925, 'weight_decay': 1.6759670303129676e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:47:40,955] Finished trial#75 with value: 0.11919040479760123 with parameters: {'num_layer': 1, 'learning_rate': 0.007249592302210633, 'weight_decay': 8.497511932964627e-09}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:49:44,025] Finished trial#76 with value: 0.1296851574212894 with parameters: {'num_layer': 2, 'learning_rate': 0.011516591431130437, 'weight_decay': 1.5403566795210185e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:51:37,445] Finished trial#77 with value: 0.13343328335832083 with parameters: {'num_layer': 1, 'learning_rate': 0.026419783081738032, 'weight_decay': 1.9667916396865026e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:53:31,986] Finished trial#78 with value: 0.12293853073463268 with parameters: {'num_layer': 1, 'learning_rate': 0.008429343849159842, 'weight_decay': 2.5498885620982845e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:55:26,145] Finished trial#79 with value: 0.12368815592203897 with parameters: {'num_layer': 1, 'learning_rate': 0.01913727442713299, 'weight_decay': 3.062073308826687e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:57:22,504] Finished trial#80 with value: 0.13043478260869568 with parameters: {'num_layer': 1, 'learning_rate': 0.03746117339301226, 'weight_decay': 6.190938489774755e-10}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 22:59:13,165] Finished trial#81 with value: 0.1214392803598201 with parameters: {'num_layer': 1, 'learning_rate': 0.015334032515746698, 'weight_decay': 5.6026534076923515e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 23:01:08,287] Finished trial#82 with value: 0.1274362818590704 with parameters: {'num_layer': 1, 'learning_rate': 0.010716494581965358, 'weight_decay': 4.438732669891753e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 23:03:00,187] Finished trial#83 with value: 0.11694152923538226 with parameters: {'num_layer': 1, 'learning_rate': 0.003619773908355151, 'weight_decay': 7.204578328111052e-08}. Best is trial#23 with value: 0.1139430284857571.\n",
      "[I 2020-04-30 23:04:53,898] Finished trial#84 with value: 0.11244377811094453 with parameters: {'num_layer': 1, 'learning_rate': 0.012652708009751688, 'weight_decay': 1.8718998497570655e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:06:46,740] Finished trial#85 with value: 0.11919040479760123 with parameters: {'num_layer': 1, 'learning_rate': 0.005080375377939276, 'weight_decay': 1.1032679713650383e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:08:40,084] Finished trial#86 with value: 0.11544227886056968 with parameters: {'num_layer': 1, 'learning_rate': 0.023765156369196242, 'weight_decay': 1.906798530529152e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:10:35,456] Finished trial#87 with value: 0.13043478260869568 with parameters: {'num_layer': 1, 'learning_rate': 0.03032038668709293, 'weight_decay': 8.932993457949915e-09}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:12:29,903] Finished trial#88 with value: 0.12593703148425783 with parameters: {'num_layer': 1, 'learning_rate': 0.0221780102000655, 'weight_decay': 1.6989003006216876e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:14:24,041] Finished trial#89 with value: 0.14167916041979012 with parameters: {'num_layer': 1, 'learning_rate': 0.04909275697103987, 'weight_decay': 2.115616692779921e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:16:43,241] Finished trial#90 with value: 0.1424287856071964 with parameters: {'num_layer': 4, 'learning_rate': 0.007762757869325388, 'weight_decay': 1.9158007962609887e-09}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:18:37,523] Finished trial#91 with value: 0.12368815592203897 with parameters: {'num_layer': 1, 'learning_rate': 0.012715710062527842, 'weight_decay': 3.721812925034691e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:20:33,070] Finished trial#92 with value: 0.12293853073463268 with parameters: {'num_layer': 1, 'learning_rate': 0.019073167747991025, 'weight_decay': 8.368699817739138e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:22:26,445] Finished trial#93 with value: 0.14092953523238383 with parameters: {'num_layer': 1, 'learning_rate': 0.0727063251822202, 'weight_decay': 2.9141907671151053e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:24:22,280] Finished trial#94 with value: 0.11844077961019495 with parameters: {'num_layer': 1, 'learning_rate': 0.013249847061974046, 'weight_decay': 2.436278230073104e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:26:28,680] Finished trial#95 with value: 0.12443778110944526 with parameters: {'num_layer': 1, 'learning_rate': 0.009805221584371535, 'weight_decay': 1.3839286368800705e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:29:52,675] Finished trial#96 with value: 0.1349325337331334 with parameters: {'num_layer': 1, 'learning_rate': 0.030800855755046198, 'weight_decay': 4.9056572474187046e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:32:57,857] Finished trial#97 with value: 0.11619190404797597 with parameters: {'num_layer': 1, 'learning_rate': 0.017659938865359062, 'weight_decay': 1.8194194333839378e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:34:50,379] Finished trial#98 with value: 0.12068965517241381 with parameters: {'num_layer': 1, 'learning_rate': 0.022907344130789653, 'weight_decay': 5.678940220282615e-08}. Best is trial#84 with value: 0.11244377811094453.\n",
      "[I 2020-04-30 23:37:03,343] Finished trial#99 with value: 0.13943028485757125 with parameters: {'num_layer': 3, 'learning_rate': 0.005746349773014915, 'weight_decay': 4.0811389848513305e-08}. Best is trial#84 with value: 0.11244377811094453.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best value: 0.11244377811094453\n",
      "best params: {'num_layer': 1, 'learning_rate': 0.012652708009751688, 'weight_decay': 1.8718998497570655e-08}\n"
     ]
    }
   ],
   "source": [
    "print('best value: {0}'.format(study.best_value))\n",
    "print('best params: {0}'.format(study.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
