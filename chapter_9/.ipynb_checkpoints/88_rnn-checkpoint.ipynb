{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../chapter_7/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, trial, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        num_layer = trial.suggest_int('num_layer', 1, 3)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        layers = []\n",
    "        num_input = input_size + hidden_size\n",
    "        power_two = 1\n",
    "        \n",
    "        while power_two < hidden_size:\n",
    "            power_two *= 2\n",
    "        num_output_last = power_two\n",
    "        \n",
    "        for i in range(num_layer):\n",
    "            power_two = 1\n",
    "            \n",
    "            while power_two < num_input:\n",
    "                power_two *= 2\n",
    "            if i == num_layer-1:\n",
    "                num_output = num_output_last\n",
    "            else:\n",
    "                num_output = power_two / 2\n",
    "            layers.append(nn.Linear(int(num_input), int(num_output)))\n",
    "            num_input = num_output\n",
    "            \n",
    "        # 順方向のRNN\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.fc2h = nn.Linear(num_output_last, hidden_size)\n",
    "        \n",
    "        # 逆方向のRNN\n",
    "        self.layers_b = nn.ModuleList(layers)\n",
    "        self.fc_b2h_b = nn.Linear(num_output_last, hidden_size)\n",
    "        \n",
    "        # output\n",
    "        self.h2o = nn.Linear(hidden_size + hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, input_b, hidden, hidden_b):\n",
    "        # 順方向のRNN\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        for layer in self.layers:\n",
    "            combined = F.relu(layer(combined))\n",
    "        hidden = F.relu(self.fc2h(combined))\n",
    "        \n",
    "        # 逆方向のRNN\n",
    "        combined_b = torch.cat((input_b, hidden_b), 1)\n",
    "        for layer in self.layers_b:\n",
    "            combined_b = F.relu(layer(combined_b))\n",
    "        hidden_b = F.relu(self.fc_b2h_b(combined_b))\n",
    "        \n",
    "        # output\n",
    "        combined_o = torch.cat((hidden, hidden_b), 1)\n",
    "        output = self.h2o(combined_o)\n",
    "        return output, hidden, hidden_b\n",
    "        \n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_id_dic(fname):\n",
    "    id_dic = {}\n",
    "    \n",
    "    with open(fname) as file:\n",
    "        for i, line in enumerate(file, 1):\n",
    "            line = line.rstrip('\\n')\n",
    "            id_dic[line] = i\n",
    "            \n",
    "    return id_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2id(sentence, id_dic):\n",
    "    import re\n",
    "    import snowballstemmer\n",
    "    \n",
    "    words_id = []\n",
    "    \n",
    "    # 文字種の統一\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # 数字の置き換え\n",
    "    sentence = re.sub(r'[0-9]+', '0', sentence)\n",
    "    \n",
    "    # '-'を' 'に変換\n",
    "    sentence = sentence.replace('-', ' ')\n",
    "    \n",
    "    words = sentence.split()\n",
    "    \n",
    "    # ステミング処理\n",
    "    stemmer = snowballstemmer.stemmer('english')\n",
    "    words2 = [stemmer.stemWord(word) for word in words]\n",
    "    words = words2\n",
    "    \n",
    "    for word in words:\n",
    "        if word in id_dic.keys():\n",
    "            words_id.append(id_dic[word])\n",
    "        else:\n",
    "            words_id.append(0)\n",
    "            \n",
    "    return words_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2vec(words_id, id_dic):\n",
    "    words_vec = []\n",
    "    \n",
    "    for id in words_id:\n",
    "        word_list = [k for k, v in id_dic.items() if v == id]\n",
    "        if len(word_list) > 0:\n",
    "            try:\n",
    "                words_vec.append(torch.from_numpy(model[word_list[0]]).view(1,-1))\n",
    "            except KeyError:\n",
    "                words_vec.append(torch.zeros(1, 300))\n",
    "        else:\n",
    "            words_vec.append(torch.zeros(1, 300))\n",
    "    \n",
    "    return torch.cat(words_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(fname, id_dic):\n",
    "    with open(fname) as file:\n",
    "        lines = file.readlines()\n",
    "        lines_vec = []\n",
    "        labels = np.zeros([len(lines), 1])\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            \n",
    "            line = line.rstrip('\\n')\n",
    "            category = line.strip('\\t')[0]\n",
    "            title = line.split('\\t')[1]\n",
    "            \n",
    "            # lines_vecの処理\n",
    "            words_id = words2id(title, id_dic)\n",
    "            words_vec = id2vec(words_id, id_dic)\n",
    "            lines_vec.append(words_vec)\n",
    "            \n",
    "            # labelsの処理\n",
    "            if category == 'b':\n",
    "                labels[i] = 0\n",
    "            elif category == 't':\n",
    "                labels[i] = 1\n",
    "            elif category == 'e':\n",
    "                labels[i] = 2\n",
    "            elif category == 'm':\n",
    "                labels[i] = 3\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "                \n",
    "    return lines_vec, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, criterion, optimizer, batch_size, words_vec_batch, words_vec_batch_b, label_batch):\n",
    "    hidden, hidden_b = rnn.initHidden(batch_size), rnn.initHidden(batch_size)\n",
    "    rnn.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    hidden, hidden_b = hidden.detach(), hidden_b.detach()\n",
    "    \n",
    "    for i in range(len(words_vec_batch)):\n",
    "        output, hidden, hidden_b = rnn(words_vec_batch[i], words_vec_batch_b[i], hidden, hidden_b)\n",
    "    loss = criterion(output, label_batch)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_accyracy(rnn, criterion, lines_vec, labels):\n",
    "    running_loss = 0\n",
    "    correct_count = 0\n",
    "    \n",
    "    for words_vec, label in zip(lines_vec, labels):\n",
    "        words_vec_batch, words_vec_batch_b, label_batch = batch_process([words_vec], [label])\n",
    "        hidden, hidden_b = rnn.initHidden(1), rnn.initHidden(1)\n",
    "        \n",
    "        for i in range(len(words_vec_batch)):\n",
    "            output, hidden, hidden_b = rnn(words_vec_batch[i], words_vec_batch_b[i], hidden, hidden_b)\n",
    "        loss = criterion(output, label)\n",
    "        running_loss += loss\n",
    "        pre_label = torch.max(output, 1)[1]\n",
    "        if pre_label == label:\n",
    "            correct_count += 1\n",
    "            \n",
    "    return running_loss / len(labels), correct_count / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(words_vec_list, label_list):\n",
    "    # words_vec_batchの処理\n",
    "    len_max = 0\n",
    "    for words_vec in words_vec_list:\n",
    "        if words_vec.size()[0] > len_max:\n",
    "            len_max = words_vec.size()[0]\n",
    "    words_vec_batch = torch.zeros(len_max, len(words_vec_list), 300)\n",
    "    for i in range(len(words_vec_list)):\n",
    "        for j in range(len(words_vec_list[i])):\n",
    "            words_vec_batch[len_max - len(words_vec_list[i]) + j, i, :] = words_vec_list[i][j]\n",
    "            \n",
    "    # words_vec_batch_bの処理\n",
    "    words_vec_batch_b = torch.zeros(len_max, len(words_vec_list), 300)\n",
    "    for i in range(len(words_vec_list)):\n",
    "        words_vec_batch_b[:, i, :] = words_vec_batch[:, len(words_vec_list) - 1 - i, :]\n",
    "    \n",
    "    # label_batchの処理\n",
    "    label_batch = torch.zeros(len(label_list)).long()\n",
    "    for i, label in enumerate(label_list):\n",
    "        label_batch[i] = label\n",
    "        \n",
    "    return words_vec_batch, words_vec_batch_b, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(trial, rnn):\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-4, 1e-0)\n",
    "    wd = trial.suggest_loguniform('weight_decay', 1e-16, 1e-12)\n",
    "    \n",
    "    optimizer = optim.SGD(rnn.parameters(), lr=lr, weight_decay = wd)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(trial, rnn, criterion, optimizer, lines_vec, labels, lines_vec_test, labels_test):\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 256)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        words_vec_list = []\n",
    "        label_list = []\n",
    "        \n",
    "        for i, dataset in enumerate(zip(lines_vec, labels), 1):\n",
    "            words_vec_list.append(dataset[0])\n",
    "            label_list.append(dataset[1])\n",
    "            \n",
    "            if i % batch_size == 0 or i == len(lines_vec):\n",
    "                words_vec_batch, words_vec_batch_b, label_batch = batch_process(words_vec_list, label_list)\n",
    "                train(rnn, criterion, optimizer, len(words_vec_list), words_vec_batch, words_vec_batch_b, label_batch)\n",
    "                words_vec_list = []\n",
    "                label_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    rnn = RNN(trial, 300, 50, 4) # RNN(d_w, d_h, L)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = make_optimizer(trial, rnn)\n",
    "    \n",
    "    id_dic = make_id_dic('../chapter_6/train.feature.txt')\n",
    "    lines_vec, labels = make_dataset('../chapter_6/train.txt', id_dic)\n",
    "    lines_vec_test, labels_test = make_dataset('../chapter_6/test.txt', id_dic)\n",
    "    \n",
    "    train_all(trial, rnn, criterion, optimizer, lines_vec, labels, lines_vec_test, labels_test)\n",
    "    \n",
    "    loss_test, accuracy_test = get_loss_and_accyracy(rnn, criterion, lines_vec_test, labels_test)\n",
    "    \n",
    "    return 1 - accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n",
      "[I 2020-04-30 19:24:27,356] Finished trial#0 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.9807899752017868, 'weight_decay': 1.9756967914508553e-16, 'batch_size': 152}. Best is trial#0 with value: 0.5809595202398801.\n",
      "[I 2020-04-30 19:25:51,222] Finished trial#1 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.028348561430050993, 'weight_decay': 8.736424780316326e-14, 'batch_size': 183}. Best is trial#0 with value: 0.5809595202398801.\n",
      "[I 2020-04-30 19:27:17,685] Finished trial#2 with value: 0.2946026986506747 with parameters: {'num_layer': 2, 'learning_rate': 0.07841298670752679, 'weight_decay': 2.0047605638462836e-15, 'batch_size': 160}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:28:44,360] Finished trial#3 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.0014033979058862703, 'weight_decay': 3.611812460762474e-15, 'batch_size': 154}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:29:57,016] Finished trial#4 with value: 0.5787106446776611 with parameters: {'num_layer': 1, 'learning_rate': 0.01828974161597231, 'weight_decay': 3.364118984483527e-15, 'batch_size': 140}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:31:43,938] Finished trial#5 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.0181031431373421, 'weight_decay': 9.963342098598076e-15, 'batch_size': 107}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:33:35,257] Finished trial#6 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.0016154701086357188, 'weight_decay': 4.2284332670767814e-16, 'batch_size': 40}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:35:20,205] Finished trial#7 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.3483335910458733, 'weight_decay': 5.591481920263187e-15, 'batch_size': 82}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:36:47,226] Finished trial#8 with value: 0.46701649175412296 with parameters: {'num_layer': 2, 'learning_rate': 0.11969796896589514, 'weight_decay': 3.667325783242241e-15, 'batch_size': 145}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:38:28,455] Finished trial#9 with value: 0.6071964017991005 with parameters: {'num_layer': 1, 'learning_rate': 0.0002940188051516783, 'weight_decay': 2.435231780288717e-14, 'batch_size': 30}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:39:41,354] Finished trial#10 with value: 0.4205397301349325 with parameters: {'num_layer': 1, 'learning_rate': 0.09642766971632812, 'weight_decay': 5.436234309067095e-13, 'batch_size': 252}. Best is trial#2 with value: 0.2946026986506747.\n",
      "[I 2020-04-30 19:40:54,690] Finished trial#11 with value: 0.2931034482758621 with parameters: {'num_layer': 1, 'learning_rate': 0.08696842859366748, 'weight_decay': 6.246141038939574e-13, 'batch_size': 250}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:42:05,124] Finished trial#12 with value: 0.41004497751124436 with parameters: {'num_layer': 1, 'learning_rate': 0.13049399528814717, 'weight_decay': 6.978512320805233e-13, 'batch_size': 249}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:43:39,751] Finished trial#13 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.7197813162132997, 'weight_decay': 9.767231961518247e-16, 'batch_size': 201}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:44:51,110] Finished trial#14 with value: 0.5809595202398801 with parameters: {'num_layer': 1, 'learning_rate': 0.004264024599836442, 'weight_decay': 1.2622227307852473e-13, 'batch_size': 206}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:46:12,915] Finished trial#15 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.04865590446244626, 'weight_decay': 6.30237011614843e-16, 'batch_size': 237}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:47:31,683] Finished trial#16 with value: 0.5809595202398801 with parameters: {'num_layer': 1, 'learning_rate': 0.3367543485137678, 'weight_decay': 3.209354114407505e-14, 'batch_size': 97}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:49:19,990] Finished trial#17 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.0041339846641619505, 'weight_decay': 1.2337398130957155e-15, 'batch_size': 216}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:50:49,644] Finished trial#18 with value: 0.5787106446776611 with parameters: {'num_layer': 2, 'learning_rate': 0.06231860521273747, 'weight_decay': 1.3573228566243209e-16, 'batch_size': 176}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:52:11,739] Finished trial#19 with value: 0.5809595202398801 with parameters: {'num_layer': 1, 'learning_rate': 0.00881023309510817, 'weight_decay': 2.7042084170066074e-13, 'batch_size': 71}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:53:46,888] Finished trial#20 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.2828660432789159, 'weight_decay': 3.010411719295768e-14, 'batch_size': 116}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:54:59,063] Finished trial#21 with value: 0.41154422788605693 with parameters: {'num_layer': 1, 'learning_rate': 0.21144714768861575, 'weight_decay': 5.299665579281643e-13, 'batch_size': 253}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:56:11,439] Finished trial#22 with value: 0.5337331334332833 with parameters: {'num_layer': 1, 'learning_rate': 0.14951841853479358, 'weight_decay': 8.866906759784818e-13, 'batch_size': 231}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:57:23,035] Finished trial#23 with value: 0.5734632683658171 with parameters: {'num_layer': 1, 'learning_rate': 0.04440954555573832, 'weight_decay': 1.860852680295662e-13, 'batch_size': 255}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:58:32,859] Finished trial#24 with value: 0.5809595202398801 with parameters: {'num_layer': 1, 'learning_rate': 0.5272549715595499, 'weight_decay': 1.5622045978550566e-15, 'batch_size': 233}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 19:59:58,393] Finished trial#25 with value: 0.36731634182908546 with parameters: {'num_layer': 2, 'learning_rate': 0.08797307286816433, 'weight_decay': 9.227464895262365e-13, 'batch_size': 177}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:01:25,521] Finished trial#26 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.011460949053477554, 'weight_decay': 6.199182727145454e-14, 'batch_size': 173}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:02:51,606] Finished trial#27 with value: 0.3733133433283359 with parameters: {'num_layer': 2, 'learning_rate': 0.06795476509329133, 'weight_decay': 3.111053299244964e-13, 'batch_size': 187}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:04:18,467] Finished trial#28 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.03169199187821259, 'weight_decay': 1.4801749802833968e-14, 'batch_size': 164}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:05:48,078] Finished trial#29 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.6872302056004048, 'weight_decay': 3.700857631195537e-16, 'batch_size': 131}. Best is trial#11 with value: 0.2931034482758621.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-30 20:07:34,383] Finished trial#30 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.08424739149274865, 'weight_decay': 2.369627568354325e-15, 'batch_size': 129}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:09:01,193] Finished trial#31 with value: 0.487256371814093 with parameters: {'num_layer': 2, 'learning_rate': 0.06603283467196047, 'weight_decay': 3.324852814611492e-13, 'batch_size': 191}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:10:28,358] Finished trial#32 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.025102086731717536, 'weight_decay': 3.0989603275796884e-13, 'batch_size': 160}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:11:53,805] Finished trial#33 with value: 0.4212893553223388 with parameters: {'num_layer': 2, 'learning_rate': 0.18387751577124956, 'weight_decay': 9.045653006281493e-13, 'batch_size': 215}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:13:21,208] Finished trial#34 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.03590969060029554, 'weight_decay': 6.670554850806445e-14, 'batch_size': 192}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:14:48,323] Finished trial#35 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.011359005196827246, 'weight_decay': 1.4156834754089524e-13, 'batch_size': 153}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:16:14,825] Finished trial#36 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.023168708395905208, 'weight_decay': 7.374702283050353e-15, 'batch_size': 178}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:17:39,974] Finished trial#37 with value: 0.48125937031484256 with parameters: {'num_layer': 2, 'learning_rate': 0.0717412652158451, 'weight_decay': 9.918524898881273e-13, 'batch_size': 188}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:19:09,479] Finished trial#38 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.2292297426983837, 'weight_decay': 4.684335267496345e-13, 'batch_size': 142}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:21:00,445] Finished trial#39 with value: 0.40179910044977507 with parameters: {'num_layer': 3, 'learning_rate': 0.4309510098123163, 'weight_decay': 2.1111470557497166e-13, 'batch_size': 219}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:22:28,389] Finished trial#40 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.014671466023511642, 'weight_decay': 2.332571737827403e-16, 'batch_size': 164}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:24:16,292] Finished trial#41 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.36140173011770843, 'weight_decay': 2.0765573079356127e-13, 'batch_size': 213}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:25:58,703] Finished trial#42 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.11242231627467346, 'weight_decay': 8.677722474280874e-14, 'batch_size': 229}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:27:46,776] Finished trial#43 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.9747031364384547, 'weight_decay': 4.079030871650872e-13, 'batch_size': 200}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:29:31,711] Finished trial#44 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.466438198119153, 'weight_decay': 7.116033396147029e-13, 'batch_size': 219}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:30:58,451] Finished trial#45 with value: 0.40254872563718136 with parameters: {'num_layer': 2, 'learning_rate': 0.11749954734188814, 'weight_decay': 4.829064083651774e-15, 'batch_size': 183}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:32:26,027] Finished trial#46 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.04483806826156018, 'weight_decay': 4.4962330046716685e-14, 'batch_size': 239}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:33:54,325] Finished trial#47 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.15990495691718157, 'weight_decay': 1.1365952208625499e-13, 'batch_size': 198}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:35:45,090] Finished trial#48 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.007337428326782533, 'weight_decay': 1.0934056287922613e-14, 'batch_size': 244}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:37:15,237] Finished trial#49 with value: 0.5442278860569716 with parameters: {'num_layer': 2, 'learning_rate': 0.08922769758210272, 'weight_decay': 2.5658438426574416e-15, 'batch_size': 149}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:38:29,674] Finished trial#50 with value: 0.5809595202398801 with parameters: {'num_layer': 1, 'learning_rate': 0.9762408273297932, 'weight_decay': 2.470324426846483e-13, 'batch_size': 171}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:39:57,715] Finished trial#51 with value: 0.38905547226386805 with parameters: {'num_layer': 2, 'learning_rate': 0.11563632578103318, 'weight_decay': 5.322337559532036e-15, 'batch_size': 181}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:41:25,199] Finished trial#52 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.05443726092439004, 'weight_decay': 1.7274803675514122e-14, 'batch_size': 207}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:42:51,079] Finished trial#53 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.2604891644925175, 'weight_decay': 8.199791126677834e-16, 'batch_size': 226}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:44:21,676] Finished trial#54 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.15606720201841953, 'weight_decay': 1.9616604566929013e-15, 'batch_size': 159}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:45:49,827] Finished trial#55 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.019566103166988362, 'weight_decay': 4.0397461251317336e-15, 'batch_size': 184}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:47:16,679] Finished trial#56 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.00024193435233813297, 'weight_decay': 6.5414504038402275e-15, 'batch_size': 173}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:48:33,053] Finished trial#57 with value: 0.5809595202398801 with parameters: {'num_layer': 1, 'learning_rate': 0.45889652044899915, 'weight_decay': 6.418379111924538e-13, 'batch_size': 120}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:50:26,392] Finished trial#58 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.03543056302326475, 'weight_decay': 1.6203172480394313e-13, 'batch_size': 207}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:51:55,838] Finished trial#59 with value: 0.3710644677661169 with parameters: {'num_layer': 2, 'learning_rate': 0.09250838457592227, 'weight_decay': 2.9972569415441383e-15, 'batch_size': 139}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:53:29,799] Finished trial#60 with value: 0.5787106446776611 with parameters: {'num_layer': 2, 'learning_rate': 0.09148882037726438, 'weight_decay': 1.479633288056925e-15, 'batch_size': 104}. Best is trial#11 with value: 0.2931034482758621.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-30 20:55:01,878] Finished trial#61 with value: 0.44677661169415295 with parameters: {'num_layer': 2, 'learning_rate': 0.06538821700107052, 'weight_decay': 2.8832561388491653e-15, 'batch_size': 149}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:56:33,596] Finished trial#62 with value: 0.5734632683658171 with parameters: {'num_layer': 2, 'learning_rate': 0.12008820647841462, 'weight_decay': 4.017040229337247e-15, 'batch_size': 139}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:58:05,155] Finished trial#63 with value: 0.6071964017991005 with parameters: {'num_layer': 2, 'learning_rate': 0.0001045406452591979, 'weight_decay': 1.014224432795627e-15, 'batch_size': 129}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 20:59:33,270] Finished trial#64 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.1927544560196321, 'weight_decay': 6.18821469447794e-16, 'batch_size': 169}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:00:59,622] Finished trial#65 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.04784724695600427, 'weight_decay': 9.041754560454737e-15, 'batch_size': 196}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:02:30,603] Finished trial#66 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.33339649051509174, 'weight_decay': 5.1683925572629105e-15, 'batch_size': 157}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:03:58,900] Finished trial#67 with value: 0.5307346326836582 with parameters: {'num_layer': 2, 'learning_rate': 0.08135151148889046, 'weight_decay': 1.805539576698213e-15, 'batch_size': 180}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:05:12,562] Finished trial#68 with value: 0.4235382308845578 with parameters: {'num_layer': 1, 'learning_rate': 0.7360753245131352, 'weight_decay': 3.7570180806572217e-13, 'batch_size': 222}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:06:42,747] Finished trial#69 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.030453222541960104, 'weight_decay': 7.381773180044114e-13, 'batch_size': 168}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:08:11,988] Finished trial#70 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.13591368177536492, 'weight_decay': 1.422970435442246e-14, 'batch_size': 188}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:09:40,994] Finished trial#71 with value: 0.4662668665667167 with parameters: {'num_layer': 2, 'learning_rate': 0.11113660500440263, 'weight_decay': 4.930154676402164e-15, 'batch_size': 184}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:11:09,868] Finished trial#72 with value: 0.4640179910044977 with parameters: {'num_layer': 2, 'learning_rate': 0.05869749114144264, 'weight_decay': 3.295391063998574e-15, 'batch_size': 179}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:12:43,682] Finished trial#73 with value: 0.3718140929535232 with parameters: {'num_layer': 2, 'learning_rate': 0.2248776309266116, 'weight_decay': 7.40596461512086e-15, 'batch_size': 134}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:14:17,444] Finished trial#74 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.2433102013583402, 'weight_decay': 7.711661802480796e-15, 'batch_size': 120}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:15:49,401] Finished trial#75 with value: 0.3493253373313343 with parameters: {'num_layer': 2, 'learning_rate': 0.19078901882469412, 'weight_decay': 5.173533409928037e-13, 'batch_size': 135}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:17:22,034] Finished trial#76 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.19929852842841544, 'weight_decay': 4.941058845803865e-13, 'batch_size': 133}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:19:01,194] Finished trial#77 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.30116224113463114, 'weight_decay': 2.1653334119863437e-15, 'batch_size': 77}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:20:35,690] Finished trial#78 with value: 0.6071964017991005 with parameters: {'num_layer': 2, 'learning_rate': 0.16977510467878398, 'weight_decay': 1.1234989125051327e-14, 'batch_size': 113}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:22:07,688] Finished trial#79 with value: 0.5734632683658171 with parameters: {'num_layer': 2, 'learning_rate': 0.07389160168284152, 'weight_decay': 2.5595307817490436e-14, 'batch_size': 96}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:23:35,915] Finished trial#80 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.0015907520178938984, 'weight_decay': 9.7337425515235e-13, 'batch_size': 144}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:25:07,905] Finished trial#81 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.5292626980887519, 'weight_decay': 5.579582980892622e-13, 'batch_size': 124}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:26:39,298] Finished trial#82 with value: 0.4145427286356822 with parameters: {'num_layer': 2, 'learning_rate': 0.10425881022931895, 'weight_decay': 2.359693080922998e-13, 'batch_size': 140}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:28:10,226] Finished trial#83 with value: 0.6071964017991005 with parameters: {'num_layer': 2, 'learning_rate': 0.24928805551340624, 'weight_decay': 3.0552214253564163e-13, 'batch_size': 154}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:29:40,568] Finished trial#84 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.03940469395979991, 'weight_decay': 7.632943359527828e-13, 'batch_size': 164}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:31:10,716] Finished trial#85 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.3661542176716345, 'weight_decay': 3.991277545570217e-13, 'batch_size': 147}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:32:26,569] Finished trial#86 with value: 0.5967016491754122 with parameters: {'num_layer': 1, 'learning_rate': 0.0960308093366002, 'weight_decay': 3.1922080489236133e-15, 'batch_size': 134}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:33:49,500] Finished trial#87 with value: 0.5472263868065967 with parameters: {'num_layer': 2, 'learning_rate': 0.13489181153933347, 'weight_decay': 5.867277586668907e-15, 'batch_size': 256}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:35:26,311] Finished trial#88 with value: 0.5809595202398801 with parameters: {'num_layer': 3, 'learning_rate': 0.5996704460726509, 'weight_decay': 1.2050781887056981e-15, 'batch_size': 193}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:36:54,275] Finished trial#89 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.1556080572545097, 'weight_decay': 1.881524855653578e-13, 'batch_size': 204}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:38:24,127] Finished trial#90 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.3897471698074307, 'weight_decay': 5.831042083345954e-13, 'batch_size': 162}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:39:56,310] Finished trial#91 with value: 0.3365817091454273 with parameters: {'num_layer': 2, 'learning_rate': 0.07232791560132842, 'weight_decay': 4.712124363599232e-15, 'batch_size': 154}. Best is trial#11 with value: 0.2931034482758621.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-04-30 21:41:26,764] Finished trial#92 with value: 0.4497751124437781 with parameters: {'num_layer': 2, 'learning_rate': 0.05954263081705069, 'weight_decay': 3.9808017288812485e-15, 'batch_size': 154}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:42:55,831] Finished trial#93 with value: 0.29760119940029983 with parameters: {'num_layer': 2, 'learning_rate': 0.07804569153550524, 'weight_decay': 2.7127375838729446e-15, 'batch_size': 176}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:44:25,405] Finished trial#94 with value: 0.5764617691154423 with parameters: {'num_layer': 2, 'learning_rate': 0.050922077090722, 'weight_decay': 2.576604981415326e-15, 'batch_size': 138}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:45:51,053] Finished trial#95 with value: 0.6071964017991005 with parameters: {'num_layer': 2, 'learning_rate': 0.07802746861386897, 'weight_decay': 8.53524247945522e-15, 'batch_size': 167}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:47:16,094] Finished trial#96 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.02517677583733956, 'weight_decay': 1.5710065647614833e-15, 'batch_size': 173}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:48:44,574] Finished trial#97 with value: 0.54047976011994 with parameters: {'num_layer': 2, 'learning_rate': 0.09777400242943748, 'weight_decay': 5.966969104419018e-15, 'batch_size': 144}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:50:12,626] Finished trial#98 with value: 0.41004497751124436 with parameters: {'num_layer': 2, 'learning_rate': 0.06960253067553485, 'weight_decay': 4.396690742379465e-15, 'batch_size': 124}. Best is trial#11 with value: 0.2931034482758621.\n",
      "[I 2020-04-30 21:51:38,887] Finished trial#99 with value: 0.5809595202398801 with parameters: {'num_layer': 2, 'learning_rate': 0.041293891758612755, 'weight_decay': 7.006332020862278e-15, 'batch_size': 152}. Best is trial#11 with value: 0.2931034482758621.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best value: 0.2931034482758621\n",
      "best params: {'num_layer': 1, 'learning_rate': 0.08696842859366748, 'weight_decay': 6.246141038939574e-13, 'batch_size': 250}\n"
     ]
    }
   ],
   "source": [
    "print('best value: {0}'.format(study.best_value))\n",
    "print('best params: {0}'.format(study.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
