{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = F.relu(self.i2h(combined))\n",
    "        output = self.i2o(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_id_dic(fname):\n",
    "    id_dic = {}\n",
    "    \n",
    "    with open(fname) as file:\n",
    "        for i, line in enumerate(file, 1):\n",
    "            line = line.rstrip('\\n')\n",
    "            id_dic[line] = i\n",
    "            \n",
    "    return id_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2id(sentence, id_dic):\n",
    "    import re\n",
    "    import snowballstemmer\n",
    "    \n",
    "    words_id = []\n",
    "    \n",
    "    # 文字種の統一\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # 数字の置き換え\n",
    "    sentence = re.sub(r'[0-9]+', '0', sentence)\n",
    "    \n",
    "    # '-'を' 'に変換\n",
    "    sentence = sentence.replace('-', ' ')\n",
    "    \n",
    "    words = sentence.split()\n",
    "    \n",
    "    # ステミング処理\n",
    "    stemmer = snowballstemmer.stemmer('english')\n",
    "    words2 = [stemmer.stemWord(word) for word in words]\n",
    "    words = words2\n",
    "    \n",
    "    for word in words:\n",
    "        if word in id_dic.keys():\n",
    "            words_id.append(id_dic[word])\n",
    "        else:\n",
    "            words_id.append(0)\n",
    "            \n",
    "    return words_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2vec(words_id, embeds):\n",
    "    words_vec = embeds(torch.Tensor(words_id).long())\n",
    "    \n",
    "    return words_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(fname, id_dic, embeds):\n",
    "    with open(fname) as file:\n",
    "        lines = file.readlines()\n",
    "        lines_vec = []\n",
    "        labels = np.zeros([len(lines), 1])\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            \n",
    "            line = line.rstrip('\\n')\n",
    "            category = line.strip('\\t')[0]\n",
    "            title = line.split('\\t')[1]\n",
    "            \n",
    "            # lines_vecの処理\n",
    "            words_id = words2id(title, id_dic)\n",
    "            words_vec = id2vec(words_id, embeds)\n",
    "            lines_vec.append(words_vec)\n",
    "            \n",
    "            # labelsの処理\n",
    "            if category == 'b':\n",
    "                labels[i] = 0\n",
    "            elif category == 't':\n",
    "                labels[i] = 1\n",
    "            elif category == 'e':\n",
    "                labels[i] = 2\n",
    "            elif category == 'm':\n",
    "                labels[i] = 3\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "                \n",
    "    return lines_vec, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, criterion, optimizer, words_vec, label):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    hidden = hidden.detach()\n",
    "    \n",
    "    for i in range(len(words_vec)):\n",
    "        output, hidden = rnn(words_vec[i:i+1], hidden)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_accyracy(rnn, criterion, lines_vec, labels):\n",
    "    running_loss = 0\n",
    "    correct_count = 0\n",
    "    \n",
    "    for words_vec, label in zip(lines_vec, labels):\n",
    "        hidden = rnn.initHidden()\n",
    "        \n",
    "        for i in range(len(words_vec)):\n",
    "            output, hidden = rnn(words_vec[i:i+1], hidden)\n",
    "        loss = criterion(output, label)\n",
    "        running_loss += loss\n",
    "        pre_label = torch.max(output, 1)[1]\n",
    "        if pre_label == label:\n",
    "            correct_count += 1\n",
    "            \n",
    "    return running_loss / len(labels), correct_count / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 訓練データ上の損失: 0.9825049042701721\t訓練データ上の正解率: 0.5970791986519378\t評価データ上の損失: 1.050036072731018\t評価データ上の正解率: 0.5734632683658171\n",
      "[2] 訓練データ上の損失: 0.90781569480896\t訓練データ上の正解率: 0.6352742932035199\t評価データ上の損失: 1.0182037353515625\t評価データ上の正解率: 0.5869565217391305\n",
      "[3] 訓練データ上の損失: 0.7531676292419434\t訓練データ上の正解率: 0.7154090994195843\t評価データ上の損失: 0.878840446472168\t評価データ上の正解率: 0.6814092953523239\n",
      "[4] 訓練データ上の損失: 0.5595049858093262\t訓練データ上の正解率: 0.7910503651001685\t評価データ上の損失: 0.6884157061576843\t評価データ上の正解率: 0.7451274362818591\n",
      "[5] 訓練データ上の損失: 0.477622389793396\t訓練データ上の正解率: 0.8227859951319978\t評価データ上の損失: 0.6375566720962524\t評価データ上の正解率: 0.7616191904047976\n",
      "[6] 訓練データ上の損失: 0.42990124225616455\t訓練データ上の正解率: 0.8425388504025464\t評価データ上の損失: 0.6150954961776733\t評価データ上の正解率: 0.767616191904048\n",
      "[7] 訓練データ上の損失: 0.4060906171798706\t訓練データ上の正解率: 0.8506833926231043\t評価データ上の損失: 0.6476395726203918\t評価データ上の正解率: 0.7691154422788605\n",
      "[8] 訓練データ上の損失: 0.37294667959213257\t訓練データ上の正解率: 0.8665980153529301\t評価データ上の損失: 0.6031543016433716\t評価データ上の正解率: 0.7781109445277361\n",
      "[9] 訓練データ上の損失: 0.37733280658721924\t訓練データ上の正解率: 0.86360232166261\t評価データ上の損失: 0.6946918368339539\t評価データ上の正解率: 0.7758620689655172\n",
      "[10] 訓練データ上の損失: 0.3431667983531952\t訓練データ上の正解率: 0.8759595581351807\t評価データ上の損失: 0.6740749478340149\t評価データ上の正解率: 0.780359820089955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "rnn = RNN(300, 50, 4) # RNN(d_w, d_h, L)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=pow(10, -3)) # lr: 検証の結果、10エポック目で最も精度が高かった数値\n",
    "\n",
    "id_dic = make_id_dic('../chapter_6/train.feature.txt')\n",
    "embeds = nn.Embedding(len(id_dic)+1, 300)\n",
    "lines_vec, labels = make_dataset('../chapter_6/train.txt', id_dic, embeds)\n",
    "lines_vec_test, labels_test = make_dataset('../chapter_6/test.txt', id_dic, embeds)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for words_vec, label in zip(lines_vec, labels):\n",
    "        train(rnn, criterion, optimizer, words_vec, label)\n",
    "        \n",
    "    loss_train, accuracy_train = get_loss_and_accyracy(rnn, criterion, lines_vec, labels)\n",
    "    loss_test, accuracy_test = get_loss_and_accyracy(rnn, criterion, lines_vec_test, labels_test)\n",
    "    print('[{0}] 訓練データ上の損失: {1}\\t訓練データ上の正解率: {2}\\t評価データ上の損失: {3}\\t評価データ上の正解率: {4}'.format(epoch + 1, loss_train, accuracy_train, loss_test, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
