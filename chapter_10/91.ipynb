{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "91.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkoPpcyd14nq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2d4808d8-3014-4b5e-e9f7-70a17308c016"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu-rjNbY2Ahd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "adda675d-48d2-4149-ac43-5ae5d5defdcb"
      },
      "source": [
        "!pip install fairseq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.17)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.38.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2035361 sha256=08246a952dd392748087109a68fd9be0c2883d055186daca3adb93fffc03fac2\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n",
            "Successfully built fairseq\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq\n",
            "Successfully installed fairseq-0.9.0 portalocker-1.7.0 sacrebleu-1.4.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utNnZ1n42Aqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!fairseq-preprocess -s ja -t en \\\n",
        "  --trainpref 'drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/90_result_train' \\\n",
        "  --validpref 'drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/90_result_dev' \\\n",
        "  --destdir 'drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin' \\\n",
        "  --thresholdsrc 5 \\\n",
        "  --thresholdtgt 5 \\\n",
        "  --workers 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK2omb7T2eqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52f0a786-f6ea-48fc-dc70-b7bc1aa4bea0"
      },
      "source": [
        "! fairseq-train 'drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin' \\\n",
        "  --save-dir 'drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints' \\\n",
        "  --fp16 \\\n",
        "  --arch transformer --share-decoder-input-output-embed \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --optimizer adam --clip-norm 1.0 \\\n",
        "  --lr 1e-3 --lr-scheduler inverse_sqrt --warmup-updates 2000 \\\n",
        "  --weight-decay 1e-4 \\\n",
        "  --dropout 0.2 \\\n",
        "  --max-epoch 5 \\\n",
        "  --max-tokens 8000"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer', attention_dropout=0.0, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=1.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=5, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=8000, max_tokens_valid=8000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=-1, warmup_updates=2000, weight_decay=0.0001)\n",
            "| [ja] dictionary: 70272 types\n",
            "| [en] dictionary: 59088 types\n",
            "| loaded 1166 examples from: drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin/valid.ja-en.ja\n",
            "| loaded 1166 examples from: drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin/valid.ja-en.en\n",
            "| drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin valid ja-en 1166 examples\n",
            "TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embed_tokens): Embedding(70272, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embed_tokens): Embedding(59088, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "| model transformer, criterion LabelSmoothedCrossEntropyCriterion\n",
            "| num. model params: 110370816 (num. trained: 110370816)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = 8000 and max sentences per GPU = None\n",
            "| no existing checkpoint found drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints/checkpoint_last.pt\n",
            "| loading train data for epoch 0\n",
            "| loaded 440288 examples from: drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin/train.ja-en.ja\n",
            "| loaded 440288 examples from: drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin/train.ja-en.en\n",
            "| drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_data-bin train ja-en 440288 examples\n",
            "| WARNING: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster\n",
            "| epoch 001:   0% 0/1710 [00:00<?, ?it/s]| WARNING: overflow detected, setting loss scale to: 64.0\n",
            "| epoch 001:   0% 1/1710 [00:00<23:56,  1.19it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "| epoch 001:   0% 2/1710 [00:01<20:57,  1.36it/s, loss=16.482, nll_loss=16.472, ppl=90908.8, wps=815, ups=0, wpb=6646.000, bsz=80.000, num_updates=1, lr=5e-07, gnorm=7.514, clip=1.000, oom=0.000, loss_scale=64.000, wall=8, train_wall=1]| WARNING: overflow detected, setting loss scale to: 32.0\n",
            "| epoch 001:  10% 179/1710 [01:38<13:00,  1.96it/s, loss=12.548, nll_loss=12.067, ppl=4290.84, wps=11449, ups=2, wpb=6831.599, bsz=237.966, num_updates=177, lr=8.85e-05, gnorm=2.637, clip=0.994, oom=0.000, loss_scale=32.000, wall=106, train_wall=98]| WARNING: overflow detected, setting loss scale to: 16.0\n",
            "| epoch 001:  11% 192/1710 [01:45<13:54,  1.82it/s, loss=12.418, nll_loss=11.917, ppl=3865.72, wps=11449, ups=2, wpb=6820.180, bsz=240.169, num_updates=189, lr=9.45e-05, gnorm=2.622, clip=0.995, oom=0.000, loss_scale=16.000, wall=113, train_wall=105]| WARNING: overflow detected, setting loss scale to: 8.0\n",
            "| epoch 001:  40% 689/1710 [06:21<09:29,  1.79it/s, loss=10.288, nll_loss=9.440, ppl=694.56, wps=12091, ups=2, wpb=6853.705, bsz=255.860, num_updates=685, lr=0.0003425, gnorm=1.879, clip=0.901, oom=0.000, loss_scale=8.000, wall=388, train_wall=378]| WARNING: overflow detected, setting loss scale to: 4.0\n",
            "| epoch 001 | loss 9.013 | nll_loss 7.958 | ppl 248.67 | wps 12423 | ups 2 | wpb 6969.724 | bsz 254.156 | num_updates 1705 | lr 0.0008525 | gnorm 1.375 | clip 0.587 | oom 0.000 | loss_scale 4.000 | wall 957 | train_wall 942\n",
            "| epoch 001 | valid on 'valid' subset | loss 7.926 | nll_loss 6.627 | ppl 98.86 | num_updates 1705\n",
            "| saved checkpoint drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints/checkpoint1.pt (epoch 1 @ 1705 updates) (writing took 58.594237327575684 seconds)\n",
            "| epoch 002 | loss 7.331 | nll_loss 6.007 | ppl 64.3 | wps 12586 | ups 2 | wpb 6970.249 | bsz 257.478 | num_updates 3415 | lr 0.000765279 | gnorm 0.724 | clip 0.105 | oom 0.000 | loss_scale 4.000 | wall 1964 | train_wall 1882\n",
            "| epoch 002 | valid on 'valid' subset | loss 7.279 | nll_loss 5.881 | ppl 58.94 | num_updates 3415 | best_loss 7.2789\n",
            "| saved checkpoint drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints/checkpoint2.pt (epoch 2 @ 3415 updates) (writing took 58.26299333572388 seconds)\n",
            "| epoch 003 | loss 6.791 | nll_loss 5.385 | ppl 41.78 | wps 12587 | ups 2 | wpb 6970.249 | bsz 257.478 | num_updates 5125 | lr 0.000624695 | gnorm 0.870 | clip 0.194 | oom 0.000 | loss_scale 4.000 | wall 2971 | train_wall 2822\n",
            "| epoch 003 | valid on 'valid' subset | loss 7.055 | nll_loss 5.613 | ppl 48.93 | num_updates 5125 | best_loss 7.0549\n",
            "| saved checkpoint drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints/checkpoint3.pt (epoch 3 @ 5125 updates) (writing took 58.72369933128357 seconds)\n",
            "| epoch 004:  25% 428/1710 [03:58<11:53,  1.80it/s, loss=6.546, nll_loss=5.100, ppl=34.31, wps=12557, ups=2, wpb=6960.397, bsz=261.981, num_updates=5553, lr=0.000600138, gnorm=1.035, clip=0.266, oom=0.000, loss_scale=4.000, wall=3269, train_wall=3058]| WARNING: overflow detected, setting loss scale to: 2.0\n",
            "| epoch 004 | loss 6.508 | nll_loss 5.058 | ppl 33.3 | wps 12581 | ups 2 | wpb 6971.257 | bsz 257.601 | num_updates 6834 | lr 0.000540975 | gnorm 0.987 | clip 0.254 | oom 0.000 | loss_scale 2.000 | wall 3979 | train_wall 3763\n",
            "| epoch 004 | valid on 'valid' subset | loss 6.946 | nll_loss 5.474 | ppl 44.44 | num_updates 6834 | best_loss 6.94595\n",
            "| saved checkpoint drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints/checkpoint4.pt (epoch 4 @ 6834 updates) (writing took 59.80575609207153 seconds)\n",
            "| epoch 005 | loss 6.321 | nll_loss 4.840 | ppl 28.65 | wps 12581 | ups 2 | wpb 6970.249 | bsz 257.478 | num_updates 8544 | lr 0.000483821 | gnorm 0.947 | clip 0.249 | oom 0.000 | loss_scale 2.000 | wall 4988 | train_wall 4703\n",
            "| epoch 005 | valid on 'valid' subset | loss 6.847 | nll_loss 5.351 | ppl 40.81 | num_updates 8544 | best_loss 6.84693\n",
            "| saved checkpoint drive/My Drive/Colab Notebooks/100_knocks/chapter_10/results/91_result_checkpoints/checkpoint5.pt (epoch 5 @ 8544 updates) (writing took 59.55458950996399 seconds)\n",
            "| done training in 5041.7 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLPkt-_PKgvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}